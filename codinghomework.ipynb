{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd00d008810b9c8467bcb3ca39aa2180e5b81b3a9acb136aab30d47954377cc5120",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0d008810b9c8467bcb3ca39aa2180e5b81b3a9acb136aab30d47954377cc5120"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# References:\n",
    "\n",
    "### https://github.com/homefish/edX_Learning_From_Data_2017/blob/master/homework_1/homework_1_PLA.ipynb\n",
    "### https://github.com/homefish/edX_Learning_From_Data_2017/blob/master/homework_2/homework_2_problem_5_6_linear_regression.ipynb\n",
    "### https://github.com/homefish/edX_Learning_From_Data_2017/blob/master/homework_2/homework_2_problem_8_9_10_Nonlinear_Transformation.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Traceback (most recent call last):\n  File \"d:\\program files\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"d:\\program files\\python39\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Program Files\\Python39\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\nModuleNotFoundError: No module named 'pip'\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 2\n",
    "number_of_runs = 1000\n",
    "number_of_training_points = 10 #N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Experiment Setup\n",
    "for run in range(number_of_runs):\n",
    "    #Create a target function f\n",
    "    pointA = np.random.uniform(-1, 1, dimension)\n",
    "    pointB = np.random.uniform(-1, 1, dimension)\n",
    "    # the line can be described by y = m*x + b where m is the slope\n",
    "    m = (pointB[1] - pointA[1]) / (pointB[0] - pointA[0])\n",
    "    b = pointB[1] - m * pointB[0]  \n",
    "    f = np.array([b, m, -1])\n",
    "\n",
    "    #Pick n points to create the dataset\n",
    "    X = np.transpose(np.array([np.ones(number_of_training_points), rnd(number_of_training_points), rnd(number_of_training_points)]))\n",
    "\n",
    "    #Evaluate these points to get the corresponding output y\n",
    "    y_f = np.sign(np.dot(X, f))\n",
    "\n",
    "    # choose hypothesis h\n",
    "\n",
    "    w_h = np.zeros(3)                       # initialize weight vector for hypothesis h\n",
    "    t = 0                                   # count number of iterations in PLA\n",
    "    \n",
    "    while True:\n",
    "        # Start PLA\n",
    "        y_h = np.sign(np.dot(X, w_h))       # classification by hypothesis\n",
    "        comp = (y_h != y_f)                 # compare classification with actual data from target function\n",
    "        wrong = np.where(comp)[0]           # indices of points with wrong classification by hypothesis h\n",
    "\n",
    "        if wrong.size == 0:\n",
    "            break\n",
    "        \n",
    "        rnd_choice = np.random.choice(wrong)        # pick a random misclassified point\n",
    "\n",
    "        # update weight vector (new hypothesis):\n",
    "        w_h = w_h +  y_f[rnd_choice] * np.transpose(X[rnd_choice])\n",
    "        t += 1\n",
    "\n",
    "    iterations_total += t\n",
    "    \n",
    "    # ------------------------------------------\n",
    "\n",
    "    # Calculate error\n",
    "    # Create data \"outside\" of training data\n",
    "\n",
    "    N_outside = 1000\n",
    "    test_x0 = np.random.uniform(-1,1,N_outside)\n",
    "    test_x1 = np.random.uniform(-1,1,N_outside)\n",
    "\n",
    "    X = np.array([np.ones(N_outside), test_x0, test_x1]).T\n",
    "\n",
    "    y_target = np.sign(X.dot(w_f))\n",
    "    y_hypothesis = np.sign(X.dot(w_h))\n",
    "    \n",
    "    ratio_mismatch = ((y_target != y_hypothesis).sum()) / N_outside\n",
    "    ratio_mismatch_total += ratio_mismatch\n",
    "\n",
    "#------------------------------------------------\n",
    "    \n",
    "print(\"Size of training data: N = \", N, \"points\")\n",
    "    \n",
    "iterations_avg = iterations_total / RUNS\n",
    "print(\"\\nAverage number of PLA iterations over\", RUNS, \"runs: t_avg = \", iterations_avg)\n",
    "\n",
    "ratio_mismatch_avg = ratio_mismatch_total / RUNS\n",
    "print(\"\\nAverage ratio for the mismatch between f(x) and h(x) outside of the training data:\")\n",
    "print(\"P(f(x)!=h(x)) = \", ratio_mismatch_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment Execution\n",
    "#For each target function, use the Perceptron Learning Algorithm (PLA) to find g\n",
    "#Start PLA with weight vector w being all zeros\n",
    "#In each iteration, PLA will choose one of the missclassified points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_points = 100 #N=100"
   ]
  }
 ]
}