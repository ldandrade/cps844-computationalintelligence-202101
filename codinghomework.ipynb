{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0d008810b9c8467bcb3ca39aa2180e5b81b3a9acb136aab30d47954377cc5120"
   }
  },
  "interpreter": {
   "hash": "eb149be0e47a3f244571d644320a48e5b4552058969aee691b20bf44c81b9cb9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# References:\n",
    "\n",
    "### https://github.com/homefish/edX_Learning_From_Data_2017/blob/master/homework_1/homework_1_PLA.ipynb\n",
    "### https://github.com/homefish/edX_Learning_From_Data_2017/blob/master/homework_2/homework_2_problem_5_6_linear_regression.ipynb\n",
    "### https://github.com/homefish/edX_Learning_From_Data_2017/blob/master/homework_2/homework_2_problem_8_9_10_Nonlinear_Transformation.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_points(lower_bound, upper_bound, dimension):\n",
    "    return np.random.uniform(lower_bound, upper_bound, size = dimension)\n",
    "\n",
    "def target_function(lower_bound, upper_bound, dimension):\n",
    "    # choose two random points A and B that belong to domain X\n",
    "    A = random_points(lower_bound, upper_bound, dimension)\n",
    "    B = random_points(lower_bound, upper_bound, dimension)\n",
    "    \n",
    "    # a line passing through 2 points A and B can be described by y = m*x + b where m is the slope\n",
    "    # where m = y - b / x\n",
    "    # and b = y - m*x\n",
    "    m = (B[1] - A[1]) / (B[0] - A[0])\n",
    "    b = B[1] - m * B[0]  \n",
    "    return np.array([b, m, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters initialization\n",
    "\n",
    "#Target function f(x) parameters\n",
    "dimension = 2\n",
    "lower_bound = -1\n",
    "upper_bound = 1\n",
    "\n",
    "#Experiment parameters\n",
    "runs = 1000\n",
    "training_points = 10\n",
    "\n",
    "#Support variables/counters\n",
    "iterations_total = 0\n",
    "ratio_mismatch_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.94819557 -0.61699252]\n",
      " [ 1.         -0.39850297  0.475566  ]\n",
      " [ 1.          0.97943618 -0.98002365]\n",
      " [ 1.          0.39821033  0.49961137]\n",
      " [ 1.          0.02823206 -0.0106774 ]]\n",
      "Target function f(x) =  -0.8358566521216493 x + 0.162055362679908\n",
      "[[ 1.          0.43432334  0.56287124]\n",
      " [ 1.          0.59052139  0.64756499]\n",
      " [ 1.          0.85209989  0.02623911]\n",
      " [ 1.          0.84482204 -0.25808625]\n",
      " [ 1.         -0.73152846 -0.12701026]\n",
      " [ 1.          0.61165844 -0.65049902]\n",
      " [ 1.         -0.14233098 -0.67255778]\n",
      " [ 1.          0.51395555  0.15301493]\n",
      " [ 1.          0.89780635 -0.38329929]\n",
      " [ 1.         -0.13333057 -0.87435516]]\n",
      "Target function f(x) =  -3.605836079400278 x + 0.5578144397297238\n",
      "[[ 1.         -0.97408852  0.83027684]\n",
      " [ 1.         -0.84939962 -0.10169081]\n",
      " [ 1.         -0.02967128 -0.78019123]\n",
      " [ 1.          0.98053246  0.93634729]\n",
      " [ 1.         -0.78570492  0.88195762]\n",
      " [ 1.         -0.01295448 -0.63476776]\n",
      " [ 1.         -0.01984862  0.28350929]\n",
      " [ 1.          0.66149902 -0.31480226]\n",
      " [ 1.          0.18739112 -0.18172775]\n",
      " [ 1.          0.88057257  0.7636557 ]]\n",
      "Target function f(x) =  -0.19452500179725463 x + 0.660841945464635\n",
      "[[ 1.         -0.72878416 -0.37035423]\n",
      " [ 1.          0.31385125  0.31617401]\n",
      " [ 1.          0.15605245 -0.47503045]\n",
      " [ 1.          0.87200561  0.43820692]\n",
      " [ 1.          0.91409554 -0.78322234]\n",
      " [ 1.         -0.56305611  0.36178154]\n",
      " [ 1.         -0.66615894 -0.29364787]\n",
      " [ 1.          0.7970472  -0.27938873]\n",
      " [ 1.          0.43616743  0.05191555]\n",
      " [ 1.         -0.40000537  0.11497371]]\n",
      "Target function f(x) =  -0.5899580694750152 x + 0.47888670192567273\n",
      "[[ 1.         -0.51008337  0.26003832]\n",
      " [ 1.          0.6597425   0.63674519]\n",
      " [ 1.         -0.17333582 -0.91281386]\n",
      " [ 1.         -0.04087466 -0.0964008 ]\n",
      " [ 1.          0.4830331  -0.4590625 ]\n",
      " [ 1.         -0.56533835  0.30286878]\n",
      " [ 1.         -0.73060019  0.26551595]\n",
      " [ 1.         -0.72031777 -0.12203042]\n",
      " [ 1.         -0.38612131  0.6824079 ]\n",
      " [ 1.         -0.30361686  0.66863005]]\n",
      "Target function f(x) =  -0.02261475577250101 x + -0.228151670321907\n",
      "[[ 1.          0.92422965  0.74909543]\n",
      " [ 1.         -0.40435286 -0.94124332]\n",
      " [ 1.          0.64487088 -0.47535377]\n",
      " [ 1.          0.86268504  0.32244695]\n",
      " [ 1.         -0.42551911  0.0650711 ]\n",
      " [ 1.          0.02913018  0.69088433]\n",
      " [ 1.         -0.84868694 -0.89137173]\n",
      " [ 1.          0.55194809  0.82460913]\n",
      " [ 1.         -0.45432853 -0.49673397]\n",
      " [ 1.         -0.24345251  0.4371844 ]]\n",
      "Target function f(x) =  2.316125477830621 x + 0.3464602766395164\n",
      "[[ 1.         -0.61534003  0.21374497]\n",
      " [ 1.          0.39741378  0.77392077]\n",
      " [ 1.          0.55959482 -0.6811656 ]\n",
      " [ 1.         -0.869316   -0.14461317]\n",
      " [ 1.         -0.18158983  0.98603491]\n",
      " [ 1.         -0.47411713 -0.45043861]\n",
      " [ 1.          0.39360916 -0.21640251]\n",
      " [ 1.         -0.59279414 -0.61818212]\n",
      " [ 1.         -0.78963465  0.64619879]\n",
      " [ 1.          0.10260138  0.77402228]]\n",
      "Target function f(x) =  -2.033275145529524 x + -0.008415986334509795\n",
      "[[ 1.         -0.2418798  -0.58066363]\n",
      " [ 1.         -0.52690137 -0.99969767]\n",
      " [ 1.         -0.23473667  0.21440073]\n",
      " [ 1.         -0.82849323  0.02654522]\n",
      " [ 1.         -0.49716586 -0.60474599]\n",
      " [ 1.         -0.88016317  0.11366696]\n",
      " [ 1.         -0.70689196  0.0499813 ]\n",
      " [ 1.          0.32130372  0.4146543 ]\n",
      " [ 1.          0.85122375  0.3021189 ]\n",
      " [ 1.         -0.59769531  0.36883578]]\n",
      "Target function f(x) =  -0.34880702442475137 x + -0.0058163846660093665\n",
      "[[ 1.         -0.382721    0.40711103]\n",
      " [ 1.         -0.98287196  0.86069428]\n",
      " [ 1.         -0.04987967 -0.037703  ]\n",
      " [ 1.         -0.80212092  0.78510491]\n",
      " [ 1.          0.75632641  0.31634716]\n",
      " [ 1.          0.93900788  0.38983351]\n",
      " [ 1.          0.77160097 -0.07234773]\n",
      " [ 1.         -0.94196801 -0.36450036]\n",
      " [ 1.         -0.88385498  0.65898748]\n",
      " [ 1.         -0.69351104  0.34337896]]\n",
      "Target function f(x) =  0.6726750704119908 x + 0.5810118403910725\n",
      "[[ 1.          0.7898709  -0.73224882]\n",
      " [ 1.          0.66551959 -0.63656384]\n",
      " [ 1.         -0.82057438  0.15397876]\n",
      " [ 1.         -0.15080953  0.31930299]\n",
      " [ 1.         -0.2192728   0.24810984]\n",
      " [ 1.         -0.30779207 -0.8403685 ]\n",
      " [ 1.          0.82803211  0.24111253]\n",
      " [ 1.          0.19690633  0.54035036]\n",
      " [ 1.          0.70034128 -0.40426389]\n",
      " [ 1.          0.85139458 -0.0250838 ]]\n",
      "Target function f(x) =  -0.662901968340959 x + 0.48913216790433406\n",
      "[[ 1.         -0.68413518 -0.66584882]\n",
      " [ 1.         -0.96551184  0.86731965]\n",
      " [ 1.         -0.01247484  0.18848353]\n",
      " [ 1.         -0.23139656  0.32693452]\n",
      " [ 1.          0.36346948 -0.13009373]\n",
      " [ 1.         -0.94864648 -0.63242203]\n",
      " [ 1.         -0.39914372 -0.06320438]\n",
      " [ 1.          0.87262365 -0.96730103]\n",
      " [ 1.          0.74543279  0.8543486 ]\n",
      " [ 1.          0.15344261 -0.90193861]]\n",
      "Target function f(x) =  -0.6546245051577971 x + -0.5549916208162342\n",
      "[[ 1.          0.4996482  -0.7059978 ]\n",
      " [ 1.          0.98021843 -0.29172013]\n",
      " [ 1.         -0.53592122 -0.48834352]\n",
      " [ 1.         -0.37911176 -0.22770793]\n",
      " [ 1.         -0.56000752  0.68599258]\n",
      " [ 1.         -0.05421582  0.43845294]\n",
      " [ 1.          0.0923896   0.19209502]\n",
      " [ 1.          0.2197591  -0.56264892]\n",
      " [ 1.          0.03413149 -0.66909041]\n",
      " [ 1.          0.64460581  0.90207896]]\n",
      "Target function f(x) =  7.72852858522029 x + -2.035373605925218\n",
      "[[ 1.00000000e+00  3.80768504e-01  7.90034905e-01]\n",
      " [ 1.00000000e+00  4.77997740e-02 -3.36246656e-01]\n",
      " [ 1.00000000e+00  2.71033538e-01 -2.70094398e-01]\n",
      " [ 1.00000000e+00 -7.44110241e-01 -6.22675224e-01]\n",
      " [ 1.00000000e+00 -6.51706328e-02 -3.72409077e-04]\n",
      " [ 1.00000000e+00 -9.70251665e-01 -7.31689786e-01]\n",
      " [ 1.00000000e+00 -4.24370470e-01  6.32375628e-01]\n",
      " [ 1.00000000e+00 -1.88181823e-01 -3.37648540e-01]\n",
      " [ 1.00000000e+00 -2.25965047e-01 -5.60589933e-03]\n",
      " [ 1.00000000e+00 -9.39039561e-01  9.08039432e-03]]\n",
      "Target function f(x) =  1.8702481965042572 x + 0.3347260219329883\n",
      "[[ 1.          0.74085016  0.76023416]\n",
      " [ 1.          0.86143856  0.74368794]\n",
      " [ 1.         -0.64979877  0.52982705]\n",
      " [ 1.         -0.08822315  0.89474629]\n",
      " [ 1.          0.53108386  0.29430333]\n",
      " [ 1.         -0.31636841 -0.48962037]\n",
      " [ 1.          0.40485993 -0.89392965]\n",
      " [ 1.         -0.03906635  0.46619658]\n",
      " [ 1.          0.25113453  0.82569231]\n",
      " [ 1.         -0.78072248 -0.14304588]]\n",
      "Target function f(x) =  0.14627843927238426 x + 0.6716921068666922\n",
      "[[ 1.          0.4313082   0.87291688]\n",
      " [ 1.          0.59523101  0.69983334]\n",
      " [ 1.          0.74506831 -0.93770051]\n",
      " [ 1.          0.29448199  0.95989165]\n",
      " [ 1.          0.4268836  -0.95680272]\n",
      " [ 1.          0.34565214  0.13434532]\n",
      " [ 1.          0.95881203  0.78490094]\n",
      " [ 1.         -0.4569878   0.27547111]\n",
      " [ 1.         -0.63502069  0.1915512 ]\n",
      " [ 1.          0.01630671 -0.20631398]]\n",
      "Target function f(x) =  -3.8758131337851967 x + -0.41708381351155\n",
      "[[ 1.         -0.88504239 -0.74322337]\n",
      " [ 1.          0.07722612 -0.21462059]\n",
      " [ 1.         -0.27669263 -0.65128305]\n",
      " [ 1.         -0.25919309  0.27865541]\n",
      " [ 1.         -0.00343382 -0.7920571 ]\n",
      " [ 1.         -0.31834896 -0.05791067]\n",
      " [ 1.          0.41479265  0.24733821]\n",
      " [ 1.          0.46206246  0.39578873]\n",
      " [ 1.         -0.24187771  0.14292347]\n",
      " [ 1.         -0.36410902 -0.1049675 ]]\n",
      "Target function f(x) =  -0.0971121298506481 x + 0.6454576076117523\n",
      "[[ 1.         -0.88576839 -0.56418411]\n",
      " [ 1.          0.25313603 -0.83738286]\n",
      " [ 1.          0.38580971  0.78171935]\n",
      " [ 1.         -0.37025594 -0.59191609]\n",
      " [ 1.          0.0174396  -0.67060258]\n",
      " [ 1.          0.33460956  0.71153435]\n",
      " [ 1.         -0.83975388  0.6715697 ]\n",
      " [ 1.         -0.12904846  0.72350605]\n",
      " [ 1.         -0.62453357 -0.10472169]\n",
      " [ 1.          0.77797203 -0.63117405]]\n",
      "Target function f(x) =  -1.2853811435231948 x + -0.2388898993839832\n",
      "[[ 1.          0.99178121  0.94901865]\n",
      " [ 1.         -0.03354606  0.27792842]\n",
      " [ 1.          0.92774306 -0.10147636]\n",
      " [ 1.          0.01060517  0.87158732]\n",
      " [ 1.          0.38152825 -0.13813788]\n",
      " [ 1.          0.35803511 -0.95122099]\n",
      " [ 1.          0.52622418  0.69556019]\n",
      " [ 1.         -0.04855678  0.13034322]\n",
      " [ 1.          0.16264964  0.41003126]\n",
      " [ 1.          0.08768717 -0.86301852]]\n",
      "Target function f(x) =  5.199342470635254 x + -0.42136362696464424\n",
      "[[ 1.         -0.64222611 -0.74336399]\n",
      " [ 1.         -0.6629465   0.75106598]\n",
      " [ 1.         -0.55042279 -0.30439374]\n",
      " [ 1.         -0.79497355  0.6624569 ]\n",
      " [ 1.          0.8113929  -0.1830095 ]\n",
      " [ 1.          0.06460173 -0.76016441]\n",
      " [ 1.          0.28195473  0.65619859]\n",
      " [ 1.         -0.01693066 -0.75421734]\n",
      " [ 1.          0.15448842  0.87880693]\n",
      " [ 1.          0.58987854  0.82735467]]\n",
      "Target function f(x) =  -0.44714597278274226 x + -0.5199231384148821\n",
      "[[ 1.         -0.71458319  0.82629909]\n",
      " [ 1.          0.93463189 -0.9831894 ]\n",
      " [ 1.          0.45135017  0.42490823]\n",
      " [ 1.          0.64087182 -0.23140517]\n",
      " [ 1.          0.33103083  0.16596445]\n",
      " [ 1.         -0.31701522 -0.71973802]\n",
      " [ 1.         -0.25039777  0.9674503 ]\n",
      " [ 1.         -0.56570996 -0.93643524]\n",
      " [ 1.         -0.23455412  0.59470018]\n",
      " [ 1.          0.598385   -0.14317885]]\n",
      "Target function f(x) =  -0.469157779865506 x + -0.3106957060664193\n",
      "[[ 1.         -0.90976203  0.65500416]\n",
      " [ 1.         -0.38051172  0.95576929]\n",
      " [ 1.          0.98942185  0.43529874]\n",
      " [ 1.          0.58831746  0.0155197 ]\n",
      " [ 1.         -0.54407847 -0.6792382 ]\n",
      " [ 1.         -0.33895086 -0.64942632]\n",
      " [ 1.          0.64327228  0.66239265]\n",
      " [ 1.         -0.89034351  0.64062248]\n",
      " [ 1.         -0.52991773  0.92919631]\n",
      " [ 1.         -0.87686295  0.04286739]]\n",
      "Target function f(x) =  0.5907115625350882 x + -0.03863370954054601\n",
      "[[ 1.          0.33791538 -0.73364088]\n",
      " [ 1.         -0.82655007  0.01384314]\n",
      " [ 1.         -0.83990241 -0.22072292]\n",
      " [ 1.          0.95493023 -0.85421612]\n",
      " [ 1.          0.85364502  0.21345091]\n",
      " [ 1.          0.39044976 -0.13563761]\n",
      " [ 1.         -0.41995927  0.50146784]\n",
      " [ 1.         -0.3031989   0.72915197]\n",
      " [ 1.         -0.38611901 -0.64230765]\n",
      " [ 1.         -0.68055824  0.21290929]]\n",
      "Target function f(x) =  0.6469344409961271 x + -0.28420511055907777\n",
      "[[ 1.          0.74415035  0.48815052]\n",
      " [ 1.         -0.94628083 -0.58474814]\n",
      " [ 1.          0.80781393  0.00229454]\n",
      " [ 1.          0.84057918 -0.85084179]\n",
      " [ 1.         -0.99062515  0.25985338]\n",
      " [ 1.         -0.48724531  0.88723111]\n",
      " [ 1.          0.82023062  0.73798568]\n",
      " [ 1.         -0.4600579  -0.77115117]\n",
      " [ 1.          0.0887231  -0.81040721]\n",
      " [ 1.          0.94937969 -0.66057689]]\n",
      "Target function f(x) =  -1.4136574030719165 x + 0.6058050929901286\n",
      "[[ 1.         -0.26178208  0.3194434 ]\n",
      " [ 1.          0.32322924 -0.70046408]\n",
      " [ 1.          0.06825261 -0.24496431]\n",
      " [ 1.          0.25226496 -0.28198756]\n",
      " [ 1.         -0.71875022  0.46339962]\n",
      " [ 1.         -0.32681483 -0.07929199]\n",
      " [ 1.          0.93055881  0.34051145]\n",
      " [ 1.          0.00253847  0.93788621]\n",
      " [ 1.          0.50902467  0.74018479]\n",
      " [ 1.         -0.88160336 -0.48502669]]\n",
      "Target function f(x) =  -1.5418891155489072 x + -0.7795420505355255\n",
      "[[ 1.          0.13661607  0.61377951]\n",
      " [ 1.         -0.18535457  0.35932188]\n",
      " [ 1.         -0.14757746 -0.13258437]\n",
      " [ 1.         -0.81182466 -0.38716923]\n",
      " [ 1.          0.92506846 -0.98025159]\n",
      " [ 1.          0.53136849  0.16444871]\n",
      " [ 1.         -0.89011695  0.89609091]\n",
      " [ 1.          0.67398489 -0.15322931]\n",
      " [ 1.         -0.56089654 -0.73546936]\n",
      " [ 1.         -0.50375631  0.15795325]]\n",
      "Target function f(x) =  1.512170193847849 x + 1.3182044373081827\n",
      "[[ 1.         -0.06250347  0.13474292]\n",
      " [ 1.          0.00372733  0.84753978]\n",
      " [ 1.          0.76019788 -0.06593204]\n",
      " [ 1.          0.37110777  0.77430091]\n",
      " [ 1.         -0.32719871  0.78283729]\n",
      " [ 1.          0.97719606  0.20751451]\n",
      " [ 1.          0.00805889  0.3576742 ]\n",
      " [ 1.         -0.79799867 -0.46552354]\n",
      " [ 1.          0.04106695  0.96784567]\n",
      " [ 1.          0.52614946 -0.2175778 ]]\n",
      "Target function f(x) =  -1.3327303963142656 x + 0.231694378528147\n",
      "[[ 1.          0.50223023  0.89570889]\n",
      " [ 1.         -0.21780608  0.36516971]\n",
      " [ 1.          0.90279777  0.68590442]\n",
      " [ 1.         -0.13623507  0.78182185]\n",
      " [ 1.          0.39977604 -0.03499519]\n",
      " [ 1.          0.1451141  -0.81294913]\n",
      " [ 1.         -0.93035164 -0.5549246 ]\n",
      " [ 1.         -0.02859258 -0.32365028]\n",
      " [ 1.         -0.89815667  0.06326457]\n",
      " [ 1.          0.18855499 -0.97657186]]\n",
      "Target function f(x) =  0.23907367081369216 x + 0.8384394858640907\n",
      "[[ 1.         -0.7376646   0.87427343]\n",
      " [ 1.          0.33540317  0.28384791]\n",
      " [ 1.          0.61344717  0.84363734]\n",
      " [ 1.         -0.92970092 -0.78154325]\n",
      " [ 1.          0.87940913 -0.48620729]\n",
      " [ 1.          0.45793158 -0.69834911]\n",
      " [ 1.          0.41263077 -0.34042366]\n",
      " [ 1.         -0.87985692 -0.35606153]\n",
      " [ 1.         -0.19327267  0.80429613]\n",
      " [ 1.          0.93714698  0.0654047 ]]\n",
      "Target function f(x) =  -12.553431884562931 x + 4.083583192820641\n",
      "[[ 1.         -0.67536556  0.1616246 ]\n",
      " [ 1.          0.00663028  0.31768968]\n",
      " [ 1.         -0.9738741   0.57073636]\n",
      " [ 1.         -0.62669421  0.4772774 ]\n",
      " [ 1.          0.75395877  0.00284468]\n",
      " [ 1.         -0.83449719 -0.28765236]\n",
      " [ 1.          0.36598896  0.780285  ]\n",
      " [ 1.          0.41427975 -0.56001792]\n",
      " [ 1.          0.94582096  0.79710488]\n",
      " [ 1.         -0.60546223 -0.96306552]]\n",
      "Target function f(x) =  -0.9894055314790408 x + -0.3721992610151548\n",
      "[[ 1.         -0.10696245  0.23191296]\n",
      " [ 1.          0.04922609  0.95401213]\n",
      " [ 1.         -0.10479065  0.64958927]\n",
      " [ 1.          0.167975   -0.77627979]\n",
      " [ 1.         -0.87900734  0.09050926]\n",
      " [ 1.          0.93998679 -0.38688309]\n",
      " [ 1.         -0.96826853  0.96105204]\n",
      " [ 1.          0.89344822 -0.39166278]\n",
      " [ 1.         -0.09665734 -0.97438518]\n",
      " [ 1.         -0.52654649 -0.06615565]]\n",
      "Target function f(x) =  0.8589664029218711 x + -0.12199908798114367\n",
      "[[ 1.          0.44296702 -0.81665532]\n",
      " [ 1.         -0.99552749  0.83015594]\n",
      " [ 1.         -0.64476655  0.43711058]\n",
      " [ 1.         -0.21473991  0.00749685]\n",
      " [ 1.         -0.90075178 -0.29502566]\n",
      " [ 1.         -0.10517378  0.70871901]\n",
      " [ 1.         -0.76218187 -0.78821647]\n",
      " [ 1.         -0.75294473  0.42453561]\n",
      " [ 1.          0.92598764 -0.87627923]\n",
      " [ 1.          0.21154328  0.65790821]]\n",
      "Target function f(x) =  0.021096282861761136 x + 0.6395122184814659\n",
      "[[ 1.          0.07926416 -0.09327773]\n",
      " [ 1.         -0.44368349 -0.69815568]\n",
      " [ 1.          0.74277693  0.79370298]\n",
      " [ 1.         -0.93425738  0.62683601]\n",
      " [ 1.         -0.49905689 -0.66629208]\n",
      " [ 1.          0.63820774  0.2102961 ]\n",
      " [ 1.          0.488342    0.879561  ]\n",
      " [ 1.          0.03226708  0.63811623]\n",
      " [ 1.          0.25288076 -0.58397969]\n",
      " [ 1.          0.28022258 -0.84311051]]\n",
      "Target function f(x) =  1.1321754510165605 x + -0.08632233366705233\n",
      "[[ 1.          0.65359682  0.09076809]\n",
      " [ 1.          0.87624263 -0.4252182 ]\n",
      " [ 1.         -0.64701674 -0.50314487]\n",
      " [ 1.          0.0031489  -0.05700734]\n",
      " [ 1.         -0.47781712 -0.18323534]\n",
      " [ 1.          0.47133957 -0.15766519]\n",
      " [ 1.         -0.73648743  0.75307466]\n",
      " [ 1.          0.93843973  0.12037704]\n",
      " [ 1.         -0.04552668  0.05670193]\n",
      " [ 1.         -0.89149313 -0.34510937]]\n",
      "Target function f(x) =  10.48052562035288 x + -9.904700595152834\n",
      "[[ 1.         -0.33073539  0.70860846]\n",
      " [ 1.         -0.37514304 -0.22534459]\n",
      " [ 1.          0.95397339 -0.03048521]\n",
      " [ 1.          0.75211495  0.46772742]\n",
      " [ 1.          0.65814615 -0.7033301 ]\n",
      " [ 1.         -0.67325824 -0.63798331]\n",
      " [ 1.          0.5506667   0.00494975]\n",
      " [ 1.         -0.33314164  0.35178793]\n",
      " [ 1.         -0.08286571 -0.18016065]\n",
      " [ 1.         -0.44214896  0.60509031]]\n",
      "Target function f(x) =  1.9390449999519512 x + 0.2656618494025311\n",
      "[[ 1.         -0.29581025  0.90337617]\n",
      " [ 1.          0.93477148  0.35255065]\n",
      " [ 1.          0.63677648 -0.90977108]\n",
      " [ 1.          0.53403866  0.05901336]\n",
      " [ 1.         -0.09154527 -0.78255283]\n",
      " [ 1.         -0.76271763  0.57186665]\n",
      " [ 1.         -0.61012788 -0.40256151]\n",
      " [ 1.         -0.84414052 -0.43034986]\n",
      " [ 1.         -0.26842895 -0.37673744]\n",
      " [ 1.         -0.4005956  -0.51949788]]\n",
      "Target function f(x) =  0.19116007711161928 x + -0.4173754735906748\n",
      "[[ 1.          0.91805528 -0.14999332]\n",
      " [ 1.          0.92965566  0.14002933]\n",
      " [ 1.         -0.30090984 -0.90332963]\n",
      " [ 1.         -0.7652055   0.86131976]\n",
      " [ 1.          0.0169595   0.89739341]\n",
      " [ 1.         -0.46298037  0.61799973]\n",
      " [ 1.         -0.5947738  -0.60776007]\n",
      " [ 1.         -0.06247645  0.29688772]\n",
      " [ 1.         -0.2640673   0.34932767]\n",
      " [ 1.         -0.42585157  0.35382269]]\n",
      "Target function f(x) =  0.5435166681720199 x + 0.3633562441899221\n",
      "[[ 1.          0.77981392 -0.0497605 ]\n",
      " [ 1.          0.89138985 -0.0141251 ]\n",
      " [ 1.          0.92726533  0.38056924]\n",
      " [ 1.         -0.29770671  0.40977901]\n",
      " [ 1.         -0.16789536  0.03629372]\n",
      " [ 1.         -0.25166271 -0.614083  ]\n",
      " [ 1.          0.88893921 -0.53748323]\n",
      " [ 1.          0.14069187 -0.58801813]\n",
      " [ 1.          0.37050436 -0.96781553]\n",
      " [ 1.         -0.28187578  0.57894894]]\n",
      "Target function f(x) =  -1.2604761467182237 x + 0.10816572874649547\n",
      "[[ 1.         -0.59899485 -0.85556837]\n",
      " [ 1.          0.37346508 -0.2234116 ]\n",
      " [ 1.          0.9794615   0.30158535]\n",
      " [ 1.         -0.46292754  0.70357051]\n",
      " [ 1.          0.20851726 -0.0313245 ]\n",
      " [ 1.         -0.19373522 -0.089214  ]\n",
      " [ 1.         -0.77303604  0.43329573]\n",
      " [ 1.         -0.89507301 -0.39804657]\n",
      " [ 1.         -0.53524998 -0.09481614]\n",
      " [ 1.          0.9626025   0.3567902 ]]\n",
      "Target function f(x) =  -0.5692263285294539 x + 0.47999074569998235\n",
      "[[ 1.          0.52526789 -0.78012084]\n",
      " [ 1.         -0.66836739 -0.20644405]\n",
      " [ 1.         -0.48212723  0.99987649]\n",
      " [ 1.          0.67325199 -0.79159154]\n",
      " [ 1.          0.2389866   0.62437216]\n",
      " [ 1.          0.96140291  0.4070926 ]\n",
      " [ 1.         -0.90497373 -0.70161453]\n",
      " [ 1.         -0.1150643   0.24647854]\n",
      " [ 1.          0.80481585 -0.21805713]\n",
      " [ 1.         -0.36562376 -0.07346786]]\n",
      "Target function f(x) =  -0.9177178302761229 x + 0.24136837565699854\n",
      "[[ 1.         -0.39075895 -0.15774535]\n",
      " [ 1.         -0.51836083 -0.60917593]\n",
      " [ 1.         -0.47774584  0.45279805]\n",
      " [ 1.          0.46059048 -0.00110577]\n",
      " [ 1.         -0.39667069 -0.40936076]\n",
      " [ 1.          0.7769311   0.38712018]\n",
      " [ 1.          0.53826341  0.14962937]\n",
      " [ 1.         -0.37613686  0.38523427]\n",
      " [ 1.         -0.8255286   0.02938621]\n",
      " [ 1.          0.15581014 -0.98576879]]\n",
      "Target function f(x) =  -21.01183367906007 x + 13.26681449547068\n",
      "[[ 1.          0.67176622 -0.0879666 ]\n",
      " [ 1.         -0.75929067  0.54047784]\n",
      " [ 1.          0.93568125 -0.3854903 ]\n",
      " [ 1.         -0.61009929  0.23558414]\n",
      " [ 1.          0.88272054  0.279462  ]\n",
      " [ 1.          0.32026181 -0.27674322]\n",
      " [ 1.          0.15567061 -0.23838739]\n",
      " [ 1.         -0.44493963  0.81113463]\n",
      " [ 1.          0.38499773 -0.95962473]\n",
      " [ 1.         -0.92883704 -0.04582646]]\n",
      "Target function f(x) =  2.3386102098351973 x + 0.4339090200422102\n",
      "[[ 1.          0.62082987 -0.67829086]\n",
      " [ 1.         -0.82678804  0.17172176]\n",
      " [ 1.          0.80781281  0.57242894]\n",
      " [ 1.         -0.45934339 -0.25207626]\n",
      " [ 1.          0.01625108  0.64982742]\n",
      " [ 1.          0.22900291  0.37961246]\n",
      " [ 1.         -0.31914591 -0.14320348]\n",
      " [ 1.         -0.14946963  0.54405535]\n",
      " [ 1.         -0.96108024  0.81970278]\n",
      " [ 1.          0.8084253   0.51890671]]\n",
      "Target function f(x) =  -0.5875092126926597 x + 0.14436012879888083\n",
      "[[ 1.         -0.15667354  0.74089386]\n",
      " [ 1.          0.11481866 -0.7361119 ]\n",
      " [ 1.          0.99322258  0.49083957]\n",
      " [ 1.          0.36721969 -0.7285239 ]\n",
      " [ 1.          0.85959998 -0.01972479]\n",
      " [ 1.          0.37509143 -0.12847958]\n",
      " [ 1.          0.1936095  -0.34846118]\n",
      " [ 1.          0.71994381 -0.31036287]\n",
      " [ 1.          0.98430492 -0.60879171]\n",
      " [ 1.          0.4850848  -0.31072041]]\n",
      "Target function f(x) =  -2.5728168607115447 x + 0.02742091562486415\n",
      "[[ 1.         -0.08030489 -0.94121972]\n",
      " [ 1.         -0.24185845  0.70420647]\n",
      " [ 1.         -0.03514446  0.70723388]\n",
      " [ 1.          0.60218981  0.01167036]\n",
      " [ 1.          0.38729461  0.23459174]\n",
      " [ 1.         -0.84455537 -0.32826592]\n",
      " [ 1.         -0.09798398  0.24172718]\n",
      " [ 1.          0.33821723  0.11347718]\n",
      " [ 1.          0.5982308   0.04488751]\n",
      " [ 1.          0.64489671  0.50602648]]\n"
     ]
    }
   ],
   "source": [
    "#Loop of <runs> experiments\n",
    "for run in range(runs):\n",
    "    #\"In each run choose a random line in the plane as your target function f (...)\"\n",
    "    f = target_function(lower_bound, upper_bound, dimension)\n",
    "    print(\"Target function f(x) = \", f[1], \"x +\", f[0])\n",
    "    \n",
    "    #\"(...) Choose the inputs x of the data set as random points uniformly in X and evaluate the target function on each x to get the corresponding           #output y (...)\"\n",
    "    X = np.transpose(np.array([np.ones(training_points), random_points(lower_bound, upper_bound, training_points), random_points(lower_bound, upper_bound, training_points)]))\n",
    "    print(X)\n",
    "    \n",
    "    #np.sign is used to map one side of the line to -1 and the other to +1, hence giving the corresponding output y to an input x\n",
    "    #np.dot is used to \n",
    "    y = np.sign(np.dot(X, f))\n",
    "\n",
    "    #\"(...) Start the PLA with the weight vector being all zeros (...) so all points are initially misclassified points. (...)\"\n",
    "    h = np.zeros(3)\n",
    "\n",
    "    iterations_count = 0\n",
    "    \n",
    "    #Start the Perceptron Learning Algorithm (PLA)\n",
    "    while True:\n",
    "        y_h = np.sign(np.dot(X, h))       # classification by hypothesis\n",
    "        comp = (y_h != y)                 # compare classification with actual data from target function\n",
    "        wrong = np.where(comp)[0]           # indices of points with wrong classification by hypothesis h\n",
    "\n",
    "        if wrong.size == 0:\n",
    "            break\n",
    "        \n",
    "        rnd_choice = np.random.choice(wrong)        # pick a random misclassified point\n",
    "\n",
    "        # update weight vector (new hypothesis):\n",
    "        h = h +  y[rnd_choice] * np.transpose(X[rnd_choice])\n",
    "        iterations_count += 1\n",
    "\n",
    "    iterations_total += iterations_count\n",
    "    \n",
    "    #Out-of-sample Data\n",
    "\n",
    "    # Calculate error\n",
    "    # Create data \"outside\" of training data\n",
    "\n",
    "    N_outside = 1000\n",
    "    test_x0 = np.random.uniform(-1,1,N_outside)\n",
    "    test_x1 = np.random.uniform(-1,1,N_outside)\n",
    "\n",
    "    X = np.array([np.ones(N_outside), test_x0, test_x1]).T\n",
    "\n",
    "    y_target = np.sign(X.dot(f))\n",
    "    y_hypothesis = np.sign(X.dot(h))\n",
    "    \n",
    "    ratio_mismatch = ((y_target != y_hypothesis).sum()) / N_outside\n",
    "    ratio_mismatch_total += ratio_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of training data: N = \", N, \"points\")\n",
    "    \n",
    "iterations_avg = iterations_total / RUNS\n",
    "print(\"\\nAverage number of PLA iterations over\", RUNS, \"runs: t_avg = \", iterations_avg)\n",
    "\n",
    "ratio_mismatch_avg = ratio_mismatch_total / RUNS\n",
    "print(\"\\nAverage ratio for the mismatch between f(x) and h(x) outside of the training data:\")\n",
    "print(\"P(f(x)!=h(x)) = \", ratio_mismatch_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick N data points (x, y) uniformly from the box [-1,1] x [-1,1]\n",
    "N = 100\n",
    "X = np.transpose(np.array([np.ones(N), rnd(N), rnd(N)]))           # input\n",
    "\n",
    "# Classify these points\n",
    "y_f = np.sign(np.dot(X, w_f))\n",
    "\n",
    "\n",
    "# plot points and color them according to their classification\n",
    "plt.plot(X[:,1][y_f == 1], X[:,2][y_f == 1], 'ro')\n",
    "plt.plot(X[:,1][y_f == -1], X[:,2][y_f == -1], 'bo')\n",
    "\n",
    "\n",
    "# plot line\n",
    "# create some data points on the line (for the plot) using the parametric vector form of a line\n",
    "# line(t) = A + t * d,  where A is a point on the line, d the directional vector and t the parameter\n",
    "d = B - A\n",
    "line_x = [A[0] + t * d[0] for t in range(-10,10)]\n",
    "line_y = [A[1] + t * d[1] for t in range(-10,10)]\n",
    "plt.plot(line_x, line_y)\n",
    "\n",
    "# plot the two points that define the line\n",
    "plt.plot(A[0], A[1], 'go')            \n",
    "plt.plot(B[0], B[1], 'go')\n",
    "\n",
    "\n",
    "# set the ranges for the x and y axis to display the [-1,1] x [-1,1] box\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESSION\n",
    "X_dagger = np.dot(np.linalg.inv(np.dot(X.T, X)), X.T)\n",
    "w_lr = np.dot(X_dagger, y_f)\n",
    "\n",
    "\n",
    "# plot classification according to w found by linear regression\n",
    "# it shows that some of the points are missclassified\n",
    "y_lr = np.sign(np.dot(X, w_lr))\n",
    "print(\"check dimensions of y_lr: \", y_lr.shape)\n",
    "\n",
    "# plot points and color them according to their classification\n",
    "plt.plot(X[:,1][y_lr == 1], X[:,2][y_lr == 1], 'ro')\n",
    "plt.plot(X[:,1][y_lr == -1], X[:,2][y_lr == -1], 'bo')\n",
    "\n",
    "# plot the correct classification line (target function)\n",
    "plt.plot(line_x, line_y, 'g')\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1,1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problems 5 and 6\n",
    "# START actual HOMEWORK now\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rnd(n): \n",
    "    return np.random.uniform(-1, 1, size = n)\n",
    "\n",
    "\n",
    "# repeat the experiment 1000 times\n",
    "RUNS = 1000\n",
    "N_sample = 100\n",
    "E_in_total = 0\n",
    "E_out_total = 0\n",
    "N_test = 1000\n",
    "\n",
    "for run in range(RUNS):\n",
    "    # choose two random points A, B in [-1,1] x [-1,1]\n",
    "    A = rnd(2)\n",
    "    B = rnd(2)\n",
    "\n",
    "    # the line can be described by y = m*x + b where m is the slope\n",
    "    m = (B[1] - A[1]) / (B[0] - A[0])\n",
    "    b = B[1] - m * B[0]  \n",
    "    w_f = np.array([b, m, -1])\n",
    "\n",
    "    #-----------------------\n",
    "\n",
    "    # Create N data points (x, y) from the target function\n",
    "    X = np.transpose(np.array([np.ones(N_sample), rnd(N_sample), rnd(N_sample)]))           # input\n",
    "    y_f = np.sign(np.dot(X, w_f))\n",
    "    \n",
    "    #-----------------------\n",
    "    \n",
    "    # LINEAR REGRESSION\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(X.T, X)), X.T)\n",
    "    w_lr = np.dot(X_dagger, y_f)\n",
    "    \n",
    "    # classification according to w found by linear regression\n",
    "    y_lr = np.sign(np.dot(X, w_lr))\n",
    "    \n",
    "    #------------------------\n",
    "    \n",
    "    # Error E_in\n",
    "    E_in = sum(y_lr != y_f) / N_sample\n",
    "    E_in_total += E_in\n",
    "\n",
    "    #------------------------\n",
    "    # Problem 6: Take 1000 test points (out of sample points) and count disagreement\n",
    "    # between y_f_test and y_lr_test\n",
    "    X_test = np.transpose(np.array([np.ones(N_test), rnd(N_test), rnd(N_test)]))\n",
    "    y_f_test = np.sign(np.dot(X_test, w_f))\n",
    "    y_lr_test = np.sign(np.dot(X_test, w_lr))\n",
    "    \n",
    "    E_out = sum(y_lr_test != y_f_test) / N_test\n",
    "    E_out_total += E_out\n",
    "    \n",
    "    \n",
    "# Average of E_in over RUNS\n",
    "E_in_avg = E_in_total / RUNS\n",
    "print(\"Average of E_in over\", RUNS, \" runs:\", E_in_avg)\n",
    "\n",
    "# Average of E_out over RUNS\n",
    "E_out_avg = E_out_total / RUNS\n",
    "print(\"Average of E_out over\", RUNS, \" runs:\", E_out_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nonlinear Transformation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create 1000 random points\n",
    "N_train = 1000\n",
    "\n",
    "def rnd(n):\n",
    "    return np.random.uniform(-1, 1, size = n)\n",
    "\n",
    "# matrix consisting of feature vectors\n",
    "X_train = np.transpose(np.array([np.ones(N_train), rnd(N_train), rnd(N_train)]))\n",
    "y_f_train = np.sign(np.multiply(X_train[:,1], X_train[:,1]) + np.multiply(X_train[:,2], X_train[:,2]) - 0.6)\n",
    "print(X_train.shape)\n",
    "print(y_f_train.shape)\n",
    "\n",
    "\n",
    "# pick 10% = 100 random indices\n",
    "indices = list(range(N_train))\n",
    "np.random.shuffle(indices)\n",
    "random_indices = indices[:(N_train // 10)]\n",
    "\n",
    "\n",
    "# flip sign in y_f_train vector\n",
    "for idx in random_indices:\n",
    "    y_f_train[idx] = (-1) * y_f_train[idx]\n",
    "\n",
    "# linear regression\n",
    "X_dagger = np.dot(np.linalg.inv(np.dot(X_train.T, X_train)), X_train.T)\n",
    "w_lr_train = np.dot(X_dagger, y_f_train)\n",
    "\n",
    "# calculate E_in\n",
    "y_lr_train = np.sign(np.dot(X_train, w_lr_train))\n",
    "E_in = sum(y_lr_train != y_f_train)  / N_train\n",
    "print(\"In sample error: \", E_in)\n",
    "\n",
    "\n",
    "# Create a plot of the classified points\n",
    "plt.plot(X_train[:,1][y_f_train == 1], X_train[:,2][y_f_train == 1], 'ro')\n",
    "plt.plot(X_train[:,1][y_f_train == -1], X_train[:,2][y_f_train == -1], 'bo')\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 8\n",
    "# Now do this 1000 times to take average\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rnd(n):\n",
    "    return np.random.uniform(-1, 1, size = n)\n",
    "\n",
    "\n",
    "RUNS = 1000\n",
    "N_train = 1000\n",
    "E_in_total = 0\n",
    "\n",
    "for run in range(RUNS):\n",
    "    \n",
    "    # create 1000 random points\n",
    "    # matrix consisting of feature vectors\n",
    "    X_train = np.transpose(np.array([np.ones(N_train), rnd(N_train), rnd(N_train)]))\n",
    "    y_f_train = np.sign(X_train[:,1] * X_train[:,1] + X_train[:,2] * X_train[:,2] - 0.6)\n",
    "\n",
    "    # pick 10% = 100 random indices\n",
    "    indices = list(range(N_train))\n",
    "    np.random.shuffle(indices)\n",
    "    random_indices = indices[:(N_train // 10)]\n",
    "\n",
    "    # flip sign in y_f_train vector\n",
    "    for idx in random_indices:\n",
    "        y_f_train[idx] = (-1) * y_f_train[idx]\n",
    "\n",
    "    # linear regression\n",
    "    X_dagger = np.dot(np.linalg.inv(np.dot(X_train.T, X_train)), X_train.T)\n",
    "    w_lr_train = np.dot(X_dagger, y_f_train)\n",
    "\n",
    "    # calculate E_in\n",
    "    y_lr_train = np.sign(np.dot(X_train, w_lr_train))\n",
    "    E_in = sum((y_lr_train != y_f_train))  / N_train\n",
    "    E_in_total += E_in\n",
    "    #print(\"In sample error: \", E_in)\n",
    "\n",
    "    \n",
    "E_in_avg = E_in_total / RUNS\n",
    "print(\"The average error E_in over\", RUNS, \"runs is: E_in_avg = \", E_in_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 9 :  transform the N = 1000 training data into the following nonlinear feature\n",
    "# vector: (1, x1, x2, x1*x2, x1*x1, x2*x2)\n",
    "\n",
    "# How to concatenate extra columns to X ?\n",
    "X = X_train\n",
    "\n",
    "# new feature matrix\n",
    "X_trans = np.transpose(np.array([np.ones(N_train), X[:,1], X[:,2], X[:,1]*X[:,2], X[:,1]*X[:,1], X[:,2]*X[:,2]]))\n",
    "\n",
    "\n",
    "# linear regression on the new \"feature matrix\"\n",
    "X_dagger_trans = np.dot(np.linalg.inv(np.dot(X_trans.T, X_trans)), X_trans.T)\n",
    "w_lr_trans = np.dot(X_dagger_trans, y_f_train)\n",
    "\n",
    "# try the different hypotheses that are given\n",
    "w_a = np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5])\n",
    "w_b = np.array([-1, -0.05, 0.08, 0.13, 1.5, 15])\n",
    "w_c = np.array([-1, -0.05, 0.08, 0.13, 15, 1.5])\n",
    "w_d = np.array([-1, -1.5, 0.08, 0.13, 0.05, 0.05])\n",
    "w_e = np.array([-1, -0.05, 0.08, 1.5, 0.15, 0.15])\n",
    "\n",
    "# compute classifications made by each hypothesis\n",
    "y_lr_trans = np.sign(np.dot(X_trans, w_lr_trans))\n",
    "y_a = np.sign(np.dot(X_trans, w_a))\n",
    "y_b = np.sign(np.dot(X_trans, w_b))\n",
    "y_c = np.sign(np.dot(X_trans, w_c))\n",
    "y_d = np.sign(np.dot(X_trans, w_d))\n",
    "y_e = np.sign(np.dot(X_trans, w_e))\n",
    "\n",
    "mismatch_lr_and_a = sum(y_a != y_lr_trans) / N_train                 # ALWAYS RESTART KERNEL !!!!!!!!!!!!                                                         \n",
    "mismatch_lr_and_b = sum(y_b != y_lr_trans) / N_train\n",
    "mismatch_lr_and_c = sum(y_c != y_lr_trans) / N_train\n",
    "mismatch_lr_and_d = sum(y_d != y_lr_trans) / N_train\n",
    "mismatch_lr_and_e = sum(y_e != y_lr_trans) / N_train\n",
    "\n",
    "print(\"mismatch between LR and a = \", mismatch_lr_and_a)\n",
    "print(\"mismatch between LR and b = \", mismatch_lr_and_b)\n",
    "print(\"mismatch between LR and c = \", mismatch_lr_and_c)\n",
    "print(\"mismatch between LR and d = \", mismatch_lr_and_d)\n",
    "print(\"mismatch between LR and e = \", mismatch_lr_and_e)\n",
    "\n",
    "print(\"The weight vector of my hypothesis is: w_LR = \", w_lr_trans)\n",
    "# Use that weight vector for problem 10\n",
    "\n",
    "\n",
    "# compare predictions made by w_lr_trans with those made by targer function\n",
    "print(\"Sanity check: E_in = \", sum(y_f_train != y_lr_trans) / N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 10\n",
    "\n",
    "RUNS = 1000\n",
    "N_test = 1000\n",
    "E_out_total = 0\n",
    "\n",
    "for run in range(RUNS):\n",
    "    \n",
    "    # create 1000 random points\n",
    "    # matrix consisting of feature vectors\n",
    "    X_test = np.transpose(np.array([np.ones(N_train), rnd(N_train), rnd(N_train)]))\n",
    "    y_f_test = np.sign(X_test[:,1] * X_test[:,1] + X_test[:,2] * X_test[:,2] - 0.6)\n",
    "\n",
    "    # pick 10% = 100 random indices\n",
    "    indices = list(range(N_test))\n",
    "    np.random.shuffle(indices)\n",
    "    random_indices = indices[:(N_test // 10)]\n",
    "\n",
    "    # flip sign in y_f_train vector\n",
    "    for idx in random_indices:\n",
    "        y_f_test[idx] = (-1) * y_f_test[idx]\n",
    "\n",
    "    # Compute classification made by my hypothesis from Problem 9\n",
    "    # first create transformed feature matrix\n",
    "    X = X_test\n",
    "    X_trans_test = np.transpose(np.array([np.ones(N_test), X[:,1], X[:,2], X[:,1]*X[:,2], X[:,1]*X[:,1], X[:,2]*X[:,2]]))\n",
    "    y_lr_trans_test = np.sign(np.dot(X_trans_test, w_lr_trans))\n",
    "    \n",
    "    # Compute disagreement between hypothesis and target function\n",
    "    E_out = sum(y_lr_trans_test != y_f_test) / N_train\n",
    "    E_out_total += E_out\n",
    "    \n",
    "E_out_avg = E_out_total / RUNS\n",
    "print(\"The average error E_out over\", RUNS, \"runs is: E_out_avg = \", E_out_avg)"
   ]
  }
 ]
}